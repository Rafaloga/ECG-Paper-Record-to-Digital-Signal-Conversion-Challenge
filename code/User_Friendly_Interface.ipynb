{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1HGhp3Ptk5UvxnuTa/mPH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafaloga/ECG-Paper-Record-to-Digital-Signal-Conversion-Challenge/blob/main/code/User_Friendly_Interface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Challenge: User Friendly App**\n",
        "For this section of the challenge, a simple web app has been developed to have a user-friendly interface. The app is a Python script for processing and analyzing electrocardiogram (ECG) images. It allows users to upload an ECG image, perform various image processing operations on it, and then extract, analyze, and visualize ECG signal data.\n",
        "The development was carried out in a Google Colab notebook to facilitate reproducibility and deployment. Streamlit and Ngrok tools were used in it. Streamlit is an open-source Python library that makes it easy to create web applications for data science and machine learning projects. It allows developers to quickly build interactive and data-driven web applications using familiar Python scripting. Ngrok is a service that provides secure tunneling to localhost. It allows you to expose a web server running on your local machine to the internet, making it accessible from anywhere. Ngrok generates a temporary public URL for your locally hosted web app, making it easy to share your work with others. To run the application, you simply need to execute the cells in the notebook."
      ],
      "metadata": {
        "id": "8PzvNp9jHtWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Packages Installation**"
      ],
      "metadata": {
        "id": "iwLDatoHJgk9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "V6kJGDiJnc1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c639f09-b612-4aa2-ce3d-33930c4b9046"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.27.2-py2.py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.1)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.8.0)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.23.5)\n",
            "Requirement already satisfied: packaging<24,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.5.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.6.0)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.5.0)\n",
            "Requirement already satisfied: tzlocal<6,>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.1)\n",
            "Collecting validators<1,>=0.2 (from streamlit)\n",
            "  Downloading validators-0.22.0-py3-none-any.whl (26 kB)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.2)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.2)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.1)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7,>=1.4->streamlit) (3.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3,>=2.7.3->streamlit) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2023.7.22)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.7.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.10.6)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Installing collected packages: watchdog, validators, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.40 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.27.2 validators-0.22.0 watchdog-3.0.0\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.0.0.tar.gz (718 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.7/718.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Building wheels for collected packages: pyngrok\n",
            "  Building wheel for pyngrok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyngrok: filename=pyngrok-7.0.0-py3-none-any.whl size=21129 sha256=fc0f96ba93fc472af18374c499762305c78576a462a128a3c185c598b93cf0e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/60/29/7b/f64332aa7e5e88fbd56d4002185ae22dcdc83b35b3d1c2cbf5\n",
            "Successfully built pyngrok\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.0.0\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "# Install the Streamlit package using pip\n",
        "!pip install streamlit\n",
        "\n",
        "# Install the Pyngrok package using pip\n",
        "!pip install pyngrok\n",
        "\n",
        "# Authenticate Ngrok using the provided token\n",
        "!ngrok authtoken 2X7qeeVbU4e8C801aLPlzLnnBQf_5BSSmdFyqybkBKwxubD74"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Web App development**\n",
        " In the following cell, the whole app is created, where users can upload an ECG image, and the code performs several image processing steps, such as correcting orientation, rotation, and smoothing. It then extracts individual ECG signal traces, analyzes them, and presents the results. Users can choose which processed image to view, select a specific ECG signal trace for detailed analysis, and download the original and smoothed ECG data in CSV format for further examination."
      ],
      "metadata": {
        "id": "neGI1rGWKyt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "# Import necessary libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import measure\n",
        "from skimage.transform import resize\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import base64\n",
        "\n",
        "# Determines the orientation of the image based on the vertical histogram\n",
        "def determine_orientation(image):\n",
        "    # Calculate a vertical histogram by summing pixel values along columns\n",
        "    hist = np.sum(image, axis=1)\n",
        "\n",
        "    # Compare the sum of the first half of the histogram to the second half\n",
        "    top_half = np.sum(hist[:len(hist)//2])\n",
        "    bottom_half = np.sum(hist[len(hist)//2:])\n",
        "\n",
        "    # If the top half has more \"weight\" than the bottom half, it's upside down\n",
        "    if top_half > bottom_half:\n",
        "        return cv2.rotate(image, cv2.ROTATE_180)\n",
        "    else:\n",
        "        return image\n",
        "\n",
        "# Function to rotate the image without losing any content\n",
        "def rotate_image(image, angle):\n",
        "    # Get the original image dimensions\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Calculate the bounding rectangle of the non-zero pixels in the image\n",
        "    rect = cv2.boundingRect(cv2.findNonZero(image))\n",
        "\n",
        "    # Extract the width and height of this bounding rectangle\n",
        "    width_rotated = rect[2]\n",
        "    height_rotated = rect[3]\n",
        "\n",
        "    # Calculate the center of the new and original image\n",
        "    center_rotated = (width_rotated // 2, height_rotated // 2)\n",
        "    center_original = (width // 2, height // 2)\n",
        "\n",
        "    # Get the rotation matrix for the given angle\n",
        "    matrix = cv2.getRotationMatrix2D(center_original, angle, 1)\n",
        "\n",
        "    # Decompose the matrix into cosine and sine values\n",
        "    cos_val = np.abs(matrix[0, 0])\n",
        "    sin_val = np.abs(matrix[0, 1])\n",
        "\n",
        "    # Calculate new dimensions after rotation\n",
        "    new_width = int((height * sin_val) + (width * cos_val))\n",
        "    new_height = int((height * cos_val) + (width * sin_val))\n",
        "\n",
        "    # Adjust the translation part of the rotation matrix\n",
        "    matrix[0, 2] += (new_width / 2) - center_original[0]\n",
        "    matrix[1, 2] += (new_height / 2) - center_original[1]\n",
        "\n",
        "    # Apply the affine transformation\n",
        "    rotated_image = cv2.warpAffine(image, matrix, (new_width, new_height), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "    return rotated_image\n",
        "\n",
        "# Corrects the image orientation based on detected lines\n",
        "def correct_orientation(img):\n",
        "    # Detect edges in the image\n",
        "    edges = cv2.Canny(img, 10, 150, apertureSize=3)\n",
        "\n",
        "    # Detect lines in the image using the Hough Transform\n",
        "    lines = cv2.HoughLinesP(edges, 1, np.pi/720, threshold=1000, minLineLength=200, maxLineGap=5)\n",
        "\n",
        "    angle = 0\n",
        "    if lines is not None:\n",
        "        angles = []\n",
        "\n",
        "        # For each detected line, compute its angle\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            angles.append(np.arctan2(y2 - y1, x2 - x1) * 180.0 / np.pi)\n",
        "\n",
        "        # Use the median angle for rotation\n",
        "        angle = np.median(angles)\n",
        "\n",
        "    return rotate_image(img, angle)  # Use the rotate_image function\n",
        "\n",
        "# Function to extract traces from a binary image\n",
        "def extract_traces(binary_global):\n",
        "    contours, _ = cv2.findContours(binary_global, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Sort the contours in descending order of their area\n",
        "    contours = sorted(contours, key=lambda x: cv2.contourArea(x), reverse=True)\n",
        "\n",
        "    # Create a list to store the cropped regions of the original image\n",
        "    cropped_original = []\n",
        "\n",
        "    # List to store the coordinates of the cropped regions\n",
        "    crops_coordinates = []\n",
        "\n",
        "    # Filter contours, crop them, and save them in the list\n",
        "    for contour in contours:\n",
        "        # Filter contours based on a minimum area threshold\n",
        "        # (1000 pixels in this case for obtaining the 2 areas mentioned before)\n",
        "        if cv2.contourArea(contour) > 1000:\n",
        "            # Get the bounding rectangle of the contour\n",
        "            x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "            # Increase the size of the bounding rectangle by 20% in each dimension\n",
        "            # beacause without this enlargement, in the next step when the traces\n",
        "            # are differentiated, some of them would have truncated areas,\n",
        "            # and therefore, the optimal result would not be achieved.\n",
        "            increase_percent = 0.20  # 20% increase\n",
        "            x -= int(w * increase_percent / 2)\n",
        "            y -= int(h * increase_percent / 2)\n",
        "            w = int(w * (1 + increase_percent))\n",
        "            h = int(h * (1 + increase_percent))\n",
        "\n",
        "            # Ensure that the coordinates are not negative\n",
        "            x = max(0, x)\n",
        "            y = max(0, y)\n",
        "\n",
        "            # Crop the region of interest from the binary image\n",
        "            cropped_img = binary_global[y:y+h, x:x+w]\n",
        "\n",
        "            # Append the cropped region and its coordinates to their respective lists\n",
        "            cropped_original.append(cropped_img)\n",
        "            crops_coordinates.append((x, y, w, h))\n",
        "\n",
        "    # Vertical edge detection using Sobel operator as the traces are separated by a vertical line.\n",
        "    sobelx = cv2.Sobel(cropped_original[0], cv2.CV_64F, 1, 0, ksize=3)\n",
        "\n",
        "    # Create a copy of the cropped image with the 12 traces\n",
        "    crop = cropped_original[0].copy()\n",
        "\n",
        "    # Dilate the edges to enhance and connect them\n",
        "    kernel = np.ones((5, 5), np.uint8)\n",
        "    dilated = cv2.dilate(sobelx, kernel, iterations=1)\n",
        "\n",
        "    # Detect lines using the Hough Line Transform\n",
        "    lines = cv2.HoughLinesP(crop.astype(np.uint8), 1, np.pi/1000, 10, minLineLength=300, maxLineGap=1)\n",
        "\n",
        "    # Draw lines on the image\n",
        "    for line in lines:\n",
        "        x1, y1, x2, y2 = line[0]\n",
        "        cv2.line(crop, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "    # Segment the image based on detected lines\n",
        "    for i in range(len(lines) - 1):\n",
        "        lead = crop[:, lines[i][0][0]:lines[i+1][0][0]]\n",
        "\n",
        "    # Find contours that correspond to the traces\n",
        "    contours, _ = cv2.findContours(crop, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Get bounding boxes and their coordinates (x, y, width, height) and filter by area\n",
        "    bounding_boxes = [(cv2.boundingRect(contour), contour) for contour in contours if cv2.contourArea(contour) > 2000]\n",
        "\n",
        "    # Get the (x, y, width, height) coordinates of the bounding boxes\n",
        "    coordinates = [(box[0], box[1], box[2], box[3]) for box, _ in bounding_boxes]\n",
        "\n",
        "    # Sort the coordinates, as they were placed un a 3x4 layout\n",
        "    # Sort the coordinates by the y-coordinate\n",
        "    coordinates.sort(key=lambda coord: coord[1])\n",
        "\n",
        "    # Divide the coordinates into three parts\n",
        "    num_parts = 3\n",
        "    part_size = len(coordinates) // num_parts\n",
        "\n",
        "    parts = [coordinates[i:i+part_size] for i in range(0, len(coordinates), part_size)]\n",
        "\n",
        "    # Sort each part by the x-coordinate\n",
        "    for i, part in enumerate(parts):\n",
        "        parts[i] = sorted(part, key=lambda coord: coord[0])\n",
        "\n",
        "    sorted_coordinates = [coord for part in parts for coord in part]\n",
        "\n",
        "    # Create a list to store cropped images\n",
        "    cropped_images = []\n",
        "    cropped_coordinates = []  # Create a list to store coordinates\n",
        "\n",
        "    # Filter contours and crop following the order, and adjust size by 20% in height only.\n",
        "    # The height adjustment is made to ensure the whole signal is captured in the rectangle\n",
        "    for index, (x, y, w, h) in enumerate(sorted_coordinates):\n",
        "        # Calculate a 20% increase in height\n",
        "        increase_percent = 0.20  # 20% increase\n",
        "        h_increase = int(h * increase_percent / 2)\n",
        "\n",
        "        # Adjust coordinates to increase size by 20% in height only\n",
        "        y -= h_increase\n",
        "        h += h_increase * 2\n",
        "\n",
        "        # Make sure coordinates are not negative\n",
        "        y = max(0, y)\n",
        "\n",
        "        # Crop the image using the adjusted coordinates\n",
        "        final = crop[y:y+h, x:x+w]\n",
        "        cropped_images.append(final)  # Add the cropped image to the list\n",
        "\n",
        "        # Store the coordinates in the cropped_coordinates list\n",
        "        cropped_coordinates.append((x, y, w, h))\n",
        "\n",
        "    # Add the 13th trace to the list\n",
        "    cropped_images.append(cropped_original[1])\n",
        "    cropped_coordinates.append(crops_coordinates[1])\n",
        "\n",
        "    return cropped_images, cropped_coordinates\n",
        "\n",
        "# Get contours from traces\n",
        "def get_contours_from_traces(cropped_images, cropped_coordinates):\n",
        "    original_contours = []\n",
        "    largest_contours = []\n",
        "    absolute_contours = []  # List to store contours in terms of the entire image\n",
        "\n",
        "\n",
        "    # Loop through all crops in cropped_images\n",
        "    for index, image in enumerate(cropped_images):\n",
        "        if index >= len(cropped_coordinates):\n",
        "            continue\n",
        "        # Find contours in the current image\n",
        "        contours = measure.find_contours(image, 0.1)\n",
        "\n",
        "        # Find the largest contour shape\n",
        "        contours_shapes = sorted([x.shape for x in contours])[::-1][0:1]\n",
        "\n",
        "        # Store the largest contour in this variable\n",
        "        largest_contour = None\n",
        "\n",
        "        # Store the original contour\n",
        "        original_contour = None\n",
        "\n",
        "        # Find the largest contour in this image\n",
        "        for contour in contours:\n",
        "            if contour.shape in contours_shapes:\n",
        "                # Resize the contour to an arbitrary value (it can vary depending on the requirements of the application)\n",
        "                # This is made to ensure all the signals have the same size, so they can be stored and compared easily.\n",
        "                resized_contour = resize(contour, (1023, 2))\n",
        "                # Store the largest contour\n",
        "                largest_contour = resized_contour\n",
        "                original_contour = contour\n",
        "\n",
        "        # Add the largest and original contour to the lists\n",
        "        largest_contours.append(largest_contour)\n",
        "        original_contours.append(original_contour)\n",
        "\n",
        "        # Now, adjust the original_contour's coordinates to be relative to the original image\n",
        "        # This way all the signals can be plotted again together\n",
        "        x_offset, y_offset, _, _ = cropped_coordinates[index]\n",
        "        absolute_contour = np.array([[y + y_offset, x + x_offset] for y, x in original_contour])\n",
        "        absolute_contours.append(absolute_contour)\n",
        "\n",
        "    return original_contours, largest_contours, absolute_contours\n",
        "\n",
        "# Show a contour\n",
        "def show_contour(contour):\n",
        "    fig, ax = plt.subplots(figsize=(5, 2))\n",
        "\n",
        "    ax.plot(contour[:, 1], contour[:, 0], linewidth=1, color='black')\n",
        "    ax.axis('image')\n",
        "    ax.invert_yaxis()\n",
        "    ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    return fig\n",
        "\n",
        "# Smooth and normalize contours\n",
        "def smooth_and_normalize_contours(absolute_contours, window_size=10):\n",
        "    original_data_list = []\n",
        "    smoothed_data_list = []\n",
        "    # Number of signals\n",
        "    num_signals = len(absolute_contours)\n",
        "\n",
        "    # Loop through the signals\n",
        "    for i in range(num_signals):\n",
        "        # Get the original data for the current signal\n",
        "        original_data = absolute_contours[i]\n",
        "\n",
        "        # Apply moving average smoothing to the current signal\n",
        "        df = pd.DataFrame(original_data, columns=['Y', 'X'])\n",
        "        central_line = df.groupby('X')['Y'].mean().reset_index()\n",
        "        central_line['Y_smooth'] = central_line['Y'].rolling(window=window_size, center=True).mean()\n",
        "\n",
        "        # Add the smoothed DataFrame to the list\n",
        "        smoothed_data_list.append(central_line)\n",
        "\n",
        "        # Add the original data to the list\n",
        "        original_data_list.append(original_data)\n",
        "\n",
        "\n",
        "    return original_data_list, smoothed_data_list\n",
        "\n",
        "# Save data to CSV\n",
        "def save_to_csv(original_data_list, smoothed_data_list):\n",
        "    # Create DataFrames from the original data and add a 'Signal' column so they can be found in the csv file\n",
        "    original_data_list_df = [pd.DataFrame(data, columns=['Y', 'X']) for data in original_data_list]\n",
        "    for i, df in enumerate(original_data_list_df):\n",
        "        df['Signal'] = i + 1  # Assign a unique signal value to each data set\n",
        "\n",
        "    # Create DataFrames from the smoothed data and add a 'Signal' column so they can be found in the csv file\n",
        "    smoothed_data_list_df = [pd.DataFrame(data, columns=['X', 'Y_smooth', 'Y']) for data in smoothed_data_list]\n",
        "    for i, df in enumerate(smoothed_data_list_df):\n",
        "        df['Signal'] = i + 1  # Assign a unique signal value to each smoothed data set\n",
        "\n",
        "    # Concatenate all the original data DataFrames into one\n",
        "    original_data = pd.concat(original_data_list_df, ignore_index=True)\n",
        "\n",
        "    # Concatenate all the smoothed data DataFrames into one\n",
        "    smoothed_data = pd.concat(smoothed_data_list_df, ignore_index=True)\n",
        "\n",
        "    # Initialize the MinMaxScaler to normalize the 'X', 'X_smooth', and 'Y' columns\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # Normalize the 'X', 'X_smooth', and 'Y' columns in the smoothed data\n",
        "    smoothed_data[['X', 'Y_smooth', 'Y']] = scaler.fit_transform(smoothed_data[['X', 'Y_smooth', 'Y']])\n",
        "\n",
        "\n",
        "    csv_filename_original = 'original_data.csv'\n",
        "    original_data.to_csv(csv_filename_original, index=False)\n",
        "\n",
        "    csv_filename = 'normalized_data.csv'\n",
        "    smoothed_data.to_csv(csv_filename, index=False)\n",
        "\n",
        "    return csv_filename_original, csv_filename\n",
        "\n",
        "# Get a download link for a CSV file\n",
        "def get_csv_download_link(csv_filename, link_name):\n",
        "    with open(csv_filename, 'rb') as f:\n",
        "        csv_data = f.read()\n",
        "    b64 = base64.b64encode(csv_data).decode()\n",
        "    href = f'<a href=\"data:file/csv;base64,{b64}\" download=\"{csv_filename}\">{link_name}</a>'\n",
        "    return href\n",
        "\n",
        "# Display graphs\n",
        "def display_graphs(original_data_list, smoothed_data_list, selected_signal_index):\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    # Create the original data graph\n",
        "    fig1, ax1 = plt.subplots(figsize=(6, 3))\n",
        "    ax1.plot(original_data_list[selected_signal_index][:, 1], original_data_list[selected_signal_index][:, 0], linewidth=1, color='black')\n",
        "    ax1.set_title(f'Signal {selected_signal_index + 1} - Original Data')\n",
        "    ax1.invert_yaxis()\n",
        "\n",
        "    # Show the original data graph in the first column\n",
        "    with col1:\n",
        "        st.pyplot(fig1)\n",
        "\n",
        "    # Create the smoothed data graph\n",
        "    fig2, ax2 = plt.subplots(figsize=(6, 3))\n",
        "    ax2.plot(smoothed_data_list[selected_signal_index]['X'], smoothed_data_list[selected_signal_index]['Y_smooth'], linewidth=1, color='black', linestyle='solid')\n",
        "    ax2.set_title(f'Signal {selected_signal_index + 1} - Smoothed Data')\n",
        "    ax2.invert_yaxis()\n",
        "\n",
        "    # Show the smoothed data graph in the second column\n",
        "    with col2:\n",
        "        st.pyplot(fig2)\n",
        "\n",
        "def show_all_images(csv_filename_original):\n",
        "    original_data = pd.read_csv(csv_filename_original)\n",
        "\n",
        "    # Determine the number of unique signals (assuming each signal has a unique identifier)\n",
        "    num_signals = original_data['Signal'].nunique()\n",
        "\n",
        "    # Create a new figure with appropriate size\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "    # Loop through each unique signal\n",
        "    for signal_id in range(1, num_signals + 1):\n",
        "        # Filter the original data for the current signal\n",
        "        original_signal_data = original_data[original_data['Signal'] == signal_id]\n",
        "\n",
        "        # Plot the data of the current signal\n",
        "        ax.plot(original_signal_data['X'], original_signal_data['Y'], label=f'Signal {signal_id}')\n",
        "\n",
        "    # Configure the plot\n",
        "    ax.set_title('All Signals - Original Data')\n",
        "    ax.invert_yaxis()  # Invert the Y-axis if necessary\n",
        "    ax.legend(loc='upper left', bbox_to_anchor=(1, 1))  # Add a legend to the plot\n",
        "\n",
        "    return fig\n",
        "\n",
        "def main():\n",
        "    st.title(\"Conversion of Paper ECG to Digital Signal\")\n",
        "\n",
        "    # Load the image\n",
        "    uploaded_file = st.file_uploader(\"Upload an ECG record image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
        "\n",
        "    if uploaded_file is not None:\n",
        "        image = cv2.imdecode(np.fromstring(uploaded_file.read(), np.uint8), cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "        # Apply transformations to the image\n",
        "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "        img_corrected = determine_orientation(gray)\n",
        "        img_rotated = correct_orientation(img_corrected)\n",
        "        blurred_image = cv2.GaussianBlur(img_rotated, (5, 5), 0.7)\n",
        "        _, binary_global = cv2.threshold(blurred_image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "        traces, traces_coordinates = extract_traces(binary_global)\n",
        "        original_contours, largest_contours, absolute_contours = get_contours_from_traces(traces, traces_coordinates)\n",
        "\n",
        "        # Create a dropdown to select which image to display\n",
        "        option = st.selectbox(\n",
        "            'Select an image to display',\n",
        "            ('Original', 'Grayscale', 'Corrected', 'Rotated', 'Smoothed', 'Binary')\n",
        "        )\n",
        "\n",
        "        # Display the selected image\n",
        "        if option == 'Original':\n",
        "            st.image(image, channels=\"BGR\", caption=\"Original Image\", use_column_width=True)\n",
        "        elif option == 'Grayscale':\n",
        "            st.image(gray, caption=\"Grayscale Image\", use_column_width=True)\n",
        "        elif option == 'Corrected':\n",
        "            st.image(img_corrected, caption=\"Corrected Image\", use_column_width=True)\n",
        "        elif option == 'Rotated':\n",
        "            st.image(img_rotated, caption=\"Rotated Image\", use_column_width=True)\n",
        "        elif option == 'Smoothed':\n",
        "            st.image(blurred_image, caption=\"Smoothed Image\", use_column_width=True)\n",
        "        elif option == 'Binary':\n",
        "            st.image(binary_global, caption=\"Binary Image\", use_column_width=True)\n",
        "\n",
        "        # Create a single dropdown to select the signal\n",
        "        signal_option = st.selectbox('Select a signal to display', [\"Signal \" + str(i+1) for i in range(len(traces))])\n",
        "        selected_signal_index = int(signal_option.split(\" \")[-1]) - 1\n",
        "\n",
        "        # Create two columns to display the trace and contour of the selected signal\n",
        "        col1, col2 = st.columns(2)\n",
        "\n",
        "        with col1:\n",
        "            st.image(traces[selected_signal_index], caption=\"Trace of \" + signal_option, use_column_width=True)\n",
        "        with col2:\n",
        "            st.pyplot(show_contour(absolute_contours[selected_signal_index]))\n",
        "\n",
        "        # Smooth and normalize\n",
        "        original_data_list, smoothed_data_list = smooth_and_normalize_contours(absolute_contours)\n",
        "\n",
        "        # Dropdown to select signal to graph\n",
        "        selected_graph_signal = st.selectbox('Select a signal to graph', [\"Signal \" + str(i+1) for i in range(len(original_data_list))])\n",
        "        selected_graph_signal_index = int(selected_graph_signal.split(\" \")[-1]) - 1\n",
        "\n",
        "        # Call the function to display graphs\n",
        "        display_graphs(original_data_list, smoothed_data_list, selected_graph_signal_index)\n",
        "\n",
        "        # Save to CSV files\n",
        "        csv_filename_original, csv_filename = save_to_csv(original_data_list, smoothed_data_list)\n",
        "\n",
        "        # Create a dropdown to select which final image to display\n",
        "        option = st.selectbox(\n",
        "            'Select an the data to display',\n",
        "            ('Original', 'Normalized')\n",
        "        )\n",
        "\n",
        "        # Display the selected image\n",
        "        if option == 'Original':\n",
        "            fig = show_all_images(csv_filename_original)\n",
        "            st.pyplot(fig)\n",
        "        elif option == 'Normalized':\n",
        "            fig = show_all_images(csv_filename)\n",
        "            st.pyplot(fig)\n",
        "\n",
        "\n",
        "\n",
        "        # Provide download links for CSV files\n",
        "        st.write('Download the data:')\n",
        "        if st.button('Download Original Data'):\n",
        "            st.markdown(get_csv_download_link(csv_filename_original, 'Download Original Data'), unsafe_allow_html=True)\n",
        "\n",
        "        if st.button('Download Normalized Data'):\n",
        "            st.markdown(get_csv_download_link(csv_filename, 'Download Normalized Data'), unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "dxx0VvOJneeh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ff8cb01-2045-4521-c4e0-9d0760bf9dca"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Streamlit App Deployment with Ngrok**\n",
        "This cell runs the Streamlit application (app.py) in the background using nohup. It then employs Pyngrok to create a public tunnel, assigning a public URL to the locally running Streamlit app on port 8501. The printed public_url represents the publicly accessible URL for the Streamlit application, allowing users to access it from a web browser or any remote location via the Internet. This combination of Streamlit and Ngrok enables the deployment of the Streamlit app with a public URL for remote access and sharing."
      ],
      "metadata": {
        "id": "mK1liXaNMoMv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup streamlit run app.py &\n",
        "\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Configura el túnel\n",
        "public_url = ngrok.connect(8501)\n",
        "print(public_url)"
      ],
      "metadata": {
        "id": "ZuaPpnX0n1qe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73397497-6cff-4752-b5b5-e6b9d3cdb56c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2023-10-24T21:27:11+0000 lvl=warn msg=\"ngrok config file found at legacy location, move to XDG location\" xdg_path=/root/.config/ngrok/ngrok.yml legacy_path=/root/.ngrok2/ngrok.yml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NgrokTunnel: \"https://e14b-35-245-66-48.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kill all Streamlit processes\n",
        "!pkill -f \"streamlit\"\n",
        "\n",
        "# Kill all Ngrok processes\n",
        "!pkill -f \"ngrok\"\n"
      ],
      "metadata": {
        "id": "aRxfRA4aqYrz"
      },
      "execution_count": 34,
      "outputs": []
    }
  ]
}